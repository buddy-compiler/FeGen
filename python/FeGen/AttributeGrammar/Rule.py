from typing import Type, List, Dict, Literal, Callable, Tuple, Any
from types import FunctionType, MethodType, ModuleType
import inspect
import copy
import ast as py_ast
import astunparse
from .RuleDefinationTransformer import LexParserConvertor, LexSemaTransformer, ParseSemaTransformer, ExecutionTimeError
import logging  
import sys
import ply.lex as lex
import ply.yacc as yacc
import os


class LexOrParseError(Exception):
    def __init__(self, msg: str):
        super().__init__(msg)


class FeGenLexer:
    def __init__(self, module):
        self.module = module
        outputdir = os.path.join(os.path.dirname(__file__), self.module.__name__)
        self.lexer = lex.lex(module=self.module, debug=False, outputdir=outputdir)

    def input(self, src: str):
        self.lexer.input(src)
        token_list = []
        while True:
            token = self.lexer.token()
            if not token:
                break
            token_list.append(token)
        return token_list
            
class FeGenParser:
    def __init__(self, module : ModuleType, lexer: FeGenLexer, grammar: "FeGenGrammar", start: str):
        self.module = module
        self.lexer = lexer
        self.grammar = grammar
        self.start = start
        self.start_func : FunctionType = getattr(self.grammar, self.start)
        if self.start_func is None:
            raise LexOrParseError("\n\n\nCan not find parse function for start rule: `{start}`, maybe you forgot to decorate `{start}` by `@parser`".format(start=start))

        # create yacc parser
        outputdir = os.path.join(os.path.dirname(__file__), self.module.__name__)
        self.__parser = yacc.yacc(module=self.module, debug=True, outputdir=outputdir, start=start)
        
        # # ParserRule lists
        # self.parser_rule_list: List[ParserRule] = parser_rule_list

        # # generated local variables when rules parsing
        # self.locals_list: List[dict] = locals_list
        

        
    def parse(self, code):
        from .ExecuteEngine import ParserTreeBuilder
        raw_data = self.__parser.parse(code)
        ExecutionEngine.WHEN = "gen_ast"
        self.startrule = self.start_func()
        builder = ParserTreeBuilder()
        # TODO: capture local variables 
        
        builder(self.startrule, raw_data)
        ExecutionEngine.WHEN = "sema"
        return self.startrule

# TODO: method lexer and parser can only be called once
class FeGenGrammar:
    """
        base class of all grammar class
    """    
    def __init__(self):
        self.plymodule = ModuleType("PLYModule", "Generated by FeGenGrammar")
        # mkdir for plymodule
        outputdir = os.path.join(os.path.dirname(__file__), self.plymodule.__name__)
        # set attr for plymodule
        setattr(self.plymodule, "__file__", outputdir)
        setattr(self.plymodule, "__package__", __package__+".PLYModule")
        if not os.path.exists(outputdir):
            os.mkdir(outputdir)
        # initialize lexer and parser
        self.lexerobj = None
        self.parserobj = None

    def __update_rules(self, self_copy):
        # declare temporary rules used in fake execution for rules generating
        def generate_template_lexer(name: str):
            return lambda self: TerminalRule(name=name)

        def generate_template_parser(name: str):
            return lambda self: ParserRule(name=name)
            
        for name in ExecutionEngine.lexerRuleFunc.keys():
            setattr(self_copy, name, MethodType(generate_template_lexer(name), self_copy))
        for name in ExecutionEngine.parserRuleFunc.keys():
            setattr(self_copy, name, MethodType(generate_template_parser(name), self_copy))
    
    def __capture_locals(func: FunctionType, *args, **kwargs):
        """execute and capture locals of func"""
        locals_dict = {}
        original_trace = sys.gettrace()
        
        def trace_function(frame, event, arg):
            if event == 'return' and frame.f_code == func.__code__:
                locals_dict.update(frame.f_locals)
            return trace_function
        
        sys.settrace(trace_function)
        try:
            res = func(*args, **kwargs) # execute
        finally:
            sys.settrace(original_trace)  # resume trace function
        
        return (res, locals_dict)
    
    def __eliminate_indent(source: str) -> Tuple[str, int]:
        lines = source.split('\n')
        indent = len(source)
        for line in lines:
            if len(line.strip()) == 0:
                continue
            indent = min(indent, len(line) - len(line.lstrip()))
        source = '\n'.join([line[indent:] for line in lines])

        
        return source, indent


    def __eliminate_decorators(source: str) -> Tuple[str, int]:
        lines = source.split('\n')
        num_decorators = 0
        for line in lines:
            if len(line) > 0 and line[0] == '@':
                num_decorators += 1
            else:
                break
        source = '\n'.join(lines[num_decorators:])
        return source, num_decorators

    def __convert_functions_and_get_ruletree(self, when: Literal["lex", "parse"]) -> List["TerminalRule"] | List["ParserRule"]:
        """
            Execute to generate rule trees for lex/parse rule generating.
            Productions of ruletree_for_parse will be folded.
            For example, for rule `one_or_more_a_or_b` defined as follow and input A B:
            
            A: 'A'
            B: 'B'
            a_or_b: A | B
            one_or_more_a_or_b: a_or_b+
            
            unfolded ruletree: one_or_more_a_or_b: {'a_or_b': {'A': 'A'}, 'a_or_b': {'B': 'B'}}
            folded ruletree:  one_or_more_a_or_b: {'a_or_b': None, 'a_or_b': None}
            
            Content of prod are folded for avoiding RecursionError which happened when generating parse rules
        """

    
        if when == "lex":
            func_dict = ExecutionEngine.lexerRuleFunc
        elif when == "parse":
            func_dict = ExecutionEngine.parserRuleFunc

        rule_trees = []
        for name, rule_def_method in func_dict.items():
            # collect file, line and col
            lines, start_line = inspect.getsourcelines(rule_def_method)
            file = inspect.getsourcefile(rule_def_method)
            source = ''.join(lines)
            source, col_offset = FeGenGrammar.__eliminate_indent(source)
            source, inc_lineno = FeGenGrammar.__eliminate_decorators(source)
            start_line += inc_lineno
            
            # get ast of source code
            parsed: py_ast.AST = py_ast.parse(source=source)
            
            # collect env
            global_env: Dict[str, Any] = rule_def_method.__globals__.copy()
            self_copy = copy.copy(self)
            self.__update_rules(self_copy)
            local_env = {"self": self_copy}
            
            # call transformer
            convertor = LexParserConvertor(
                when=ExecutionEngine.WHEN, func_name=name, file=file, start_lineno=start_line, start_column=col_offset, global_env={**global_env, **local_env}
            )
            converted_func_ast = convertor.visit(parsed)
            converted_func_code_str = astunparse.unparse(converted_func_ast)
            converted_func_code = compile(converted_func_code_str, f"lexer_rule_{name}", mode = "exec")
            exec(converted_func_code, rule_def_method.__globals__, local_env)
            converted_func: FunctionType = local_env[name]
            ExecutionEngine.lexerRulesWhenLex[name] = converted_func
            logging.debug(f"Code generated for {when} function {name}: " + converted_func_code_str)
            
            # execute to generate folded ruletree
            rule_tree = converted_func(self_copy)
            rule_trees.append(rule_tree)
            
            # update functions of self
            setattr(self, name, MethodType(converted_func, self))
        return rule_trees
    
    
    def lexer(self) -> FeGenLexer:
        """return lexer of attribute grammar
        """
        if self.lexerobj is not None:
            return self.lexerobj
        from .ExecuteEngine import LexerProdGen
       
        
        # process source code and generate code for lexer
        ExecutionEngine.WHEN = "lex"
        # generated rule trees for parse rule generating
        ruletrees_for_lex : List[TerminalRule] = self.__convert_functions_and_get_ruletree(ExecutionEngine.WHEN)
        
        attr_dict = self.plymodule.__dict__
        # insert tokens tuple
        attr_dict.update({"tokens": tuple([r.name for r in ruletrees_for_lex])})
        gen = LexerProdGen()
        # insert lex defination
        for lexRule in ruletrees_for_lex:
            name = lexRule.name
            prod = lexRule.production
            lexprod = gen(prod)
            logging.debug(f"Regular expression for rule '{name}' is {lexprod}")
            attr_dict.update({"t_" + name:  lexprod})
        # insert ignore and skip
        # TODO: skip
        def t_error(t):
            print(f"Illegal character '{t.value[0]}'")
            t.lexer.skip(1)

        attr_dict.update({"t_error": t_error, "t_ignore": ' \t'})

        # generate PLY lexer
        self.lexerobj = FeGenLexer(self.plymodule)
        return self.lexerobj
    
    def parser(self, lexer: FeGenLexer, start = None) -> FeGenParser:
        if self.parserobj is not None:
            return self.parserobj
        from .ExecuteEngine import ParserProdGen
        # process source code and generate code for lexer
        ExecutionEngine.WHEN = "parse"
        # generated rule trees for parse rule generating
        ruletrees_for_parse : List[ParserRule] = self.__convert_functions_and_get_ruletree(ExecutionEngine.WHEN)
        
        # generate PLY function
        attr_dict = self.plymodule.__dict__
        gen = ParserProdGen(attr_dict)
        for rule in ruletrees_for_parse:
            gen(rule)

        self.parserobj = FeGenParser(self.plymodule, lexer, self, start)
        return self.parserobj
        # # update parse functions of self
        # for name, parse_func in ExecutionEngine.parserRulesWhenParse.items():
        #     actual_func = getattr(self, name)
        #     assert actual_func is not None and isinstance(actual_func, FunctionType)
        #     parse_func.__globals__ = actual_func.__globals__
        #     setattr(self, name, MethodType(parse_func, self))
        

        
        # # generate parse rules
        # # mapping function name and local variables
        # parser_rule_list: List[ParserRule] = []
        # locals_list: List[dict] = []
        # for name, parse_func in ExecutionEngine.parserRulesWhenParse.items():
        #     # execute lex function 
        #     parseRule, local_vars = FeGenGrammar.__capture_locals(parse_func, self)
        #     assert isinstance(parseRule, ParserRule)
        #     parseRule.name = name
        #     parser_rule_list.append(parseRule)
        #     locals_list.append(local_vars)
        
        
        # attr_dict = self.plymodule.__dict__
        # gen = ParserProdGen(attr_dict)
        # # insert parse defination
        # for parser_rule in parser_rule_list:
        #     gen(parser_rule)
        # generate PLY lexer



class Production:
    def __init__(self):
        self.content = None

    def getText(self):
        raise NotImplementedError()

class ExecutionEngine:
    """Stores global variables
    """
    WHEN: Literal['lex', 'parse', 'gen_ast' 'sema'] = "lex"
    GRAMMAR_CLS = None
    # method that decorated by lexer
    lexerRuleFunc : Dict[str, Callable] = {}
    # method that decorated by parser
    parserRuleFunc : Dict[str, Callable] = {}
    
    parserRulesWhenParse : Dict[str, Callable] = {}
    parserRulesWhenSema : Dict[str, Callable] = {}
    lexerRulesWhenLex : Dict[str, Callable] = {}
    lexerRulesWhenSema : Dict[str, Callable] = {}
    skipRules : Dict[str, Callable] = {}




def parser(parser_rule_defination: FunctionType):
    """An decorator to mark a function in a subclass of FeGenGrammar that defines a parse rule, ExecutionEngine.WHEN decides action of function.

    Args:
        parser_rule_defination (FunctionType): lex defining function
    """
    # assert function only have one parameter: self
    sig = inspect.signature(parser_rule_defination).parameters
    assert len(sig) == 1, f"lexer defining function should only have one parameter: self"
    name = parser_rule_defination.__name__
    ExecutionEngine.parserRuleFunc[name] = parser_rule_defination
    return parser_rule_defination


def lexer(lexer_rule_defination: FunctionType):
    """An decorator to mark a function in a subclass of FeGenGrammar that defines a lex rule, ExecutionEngine.WHEN decides action of function.

    Args:
        lexer_rule_defination (FunctionType): lex defining function
    """
    # assert function only have one parameter: self
    sig = inspect.signature(lexer_rule_defination).parameters
    assert len(sig) == 1, f"lexer defining function should only have one parameter: self"
    name = lexer_rule_defination.__name__
    ExecutionEngine.lexerRuleFunc[name] = lexer_rule_defination
    return lexer_rule_defination


def skip(skip_rule_defination):
    def warp(*args, **kwargs):
        name = skip_rule_defination.__name__
        ExecutionEngine.lexerRulesWhenLex[name] = skip_rule_defination
        return skip_rule_defination(*args, **kwargs)
    return warp


class ExecutableWarpper:
    def __init__(self, executable: FunctionType, whenexecute: Tuple[Literal['lex', 'parse', 'get_ast', 'sema']]):
        self.executable = executable
        self.whenexecute = whenexecute

    def __call__(self, *args, **kwds):
        if ExecutionEngine.WHEN in self.whenexecute:
            return self.executable(*args, **kwds)
        else:
            raise ExecutionTimeError(self.executable, "Function execute in wrong time, expected in {when} time, but now it is time to {time}".format(when=self.whenexecute, time=ExecutionEngine.WHEN))


def execute_when(*when):
    """mark function to execute at correct time
        when can be:
        * lex
        * parse
        * get_ast
        * sema
    """
    for item in when:
        assert isinstance(item, str), "function `execute_when` accepts only string values."
    def decorator(func):
        f = lambda *args, **kwds: ExecutableWarpper(func, when)(*args, **kwds)
        setattr(f, "execute_when", when)
        return f
    return decorator


class ChatSet(Production):
    """
        char_set("A-Z") --> [A-Z]
    """
    def __init__(self, charset: str):
        super().__init__()
        self.charset = charset

def char_set(charset: str):
    return ChatSet(charset)


class OneOrMore(Production):
    """
        one_or_more(A) --> A+ 
    """
    def __init__(self, prod: Production):
        super().__init__()
        self.template_prod = prod
        self.children : List[Production] = [prod]

    @execute_when("sema")
    def getText(self):
        if len(self.children) == 0:
            return ""
        else:
            texts = [child.getText() for child in self.children]
            return " ".join(texts)

def one_or_more(prod: Production):
    return OneOrMore(prod)


class ZeroOrMore(Production):
    """
        zero_or_more(A) --> A*
    """
    def __init__(self, prod: Production):
        super().__init__()
        self.template_prod = prod
        self.children : List[Production] = [prod]

    @execute_when("sema")
    def getText(self):
        texts = [child.getText() for child in self.children]
        return " ".join(texts)

def zero_or_more(prod: Production):
    return ZeroOrMore(prod)


class ZeroOrOne(Production):
    """
        zero_or_one(A) --> A?
    """
    def __init__(self, prod: Production):
        super().__init__()
        self.prod = prod

    @execute_when("sema")
    def getText(self):
        if self.prod.content is None:
            return ""
        return self.prod.getText()

def zero_or_one(prod: Production):
    return ZeroOrOne(prod)


class Concat(Production):
    """
        concat(A, B) -->  A B
    """
    def __init__(self, *args):
        super().__init__()
        self.rules : List[Production] = args

    @execute_when("sema")
    def getText(self):
        texts = [rule.getText() for rule in self.rules]
        return " ".join(texts)

def concat(*args):
    return Concat(*args)

class Alternate(Production):
    """
        alternate(A, B) --> A | B
    """
    def __init__(self, *args):
        super().__init__()
        self.template_alt_funcs : Tuple[FunctionType] = args
        for alt_func in self.template_alt_funcs:
            sig = inspect.signature(alt_func).parameters
            assert len(sig) == 0 and f"alt functions {alt_func.__name__} should not have any parameter"
 
        # During lex and parse time, template_alt_func will generate folded rule tree to avoid recursion
        self.template_alts : List[Production] = []
        if ExecutionEngine.WHEN in ("lex", "parse"):
            self.template_alts = [func() for func in self.template_alt_funcs]
        # the actual matched sub prod
        self.prod : Production = None

    @execute_when("sema")
    def getText(self):
        return self.prod.getText()

def alternate(*args):
    return Alternate(*args)

class Attribute:
    def __init__(self, name: str, ty: Type, init = None):
        self.name = name
        self.ty = ty
        self.value = init

    def set(self, value):
        assert (isinstance(value, self.ty) or value is None) and f"mismatch type."
        self.value = value

class Rule(Production):
    def __init__(self, production = None, name = "UNKNOWN"):
        super().__init__()
        self.production = None
        self.name = name
        self.setProduction(production)
        
    def setProduction(self, prod):
        self.production = prod


class ParserRule(Rule):
    def __init__(self, production = None, name = "UNKNOWN"):
        super().__init__(production, name)
        self.attributes : Dict[str, Attribute] = []
        self.visited = False
        self.children : List[Rule] = []
    
    @execute_when("parse", "gen_ast")
    def setProduction(self, prod):
        super().setProduction(prod)
    
    
    @execute_when("sema")
    def new_attr(self, name: str, ty: Type, init = None):
        assert name not in self.attributes and f"Attribute {name} already exists."
        attr = Attribute(name, ty, init)
        self.attributes[name] = attr
        return attr
    
    
    @execute_when("sema")
    def set_attr(self, name: str, value):
        assert name not in self.attributes and f"Attribute {name} does exist."
        attr = self.attributes[name]
        attr.set(value)
    
    
    @execute_when("sema")
    def get_attr(self, name: str):
        assert name in self.attributes and f"Attribute {name} does not exist."
        if not self.visited:
            self.visit()
        return self.attributes[name]

    
    @execute_when("sema")
    def visit(self):
        """
            visit tree node 
        """
        self.visited = True
        # TODO: VISIT

    @execute_when("sema")
    def getText(self):
        return self.production.getText()
            
class TerminalRule(Rule):
    def __init__(self, production = None, name = "UNKNOWN"):
        super().__init__(production, name)

    
    @execute_when("lex", "parse", "gen_ast")
    def setProduction(self, prod):
        return super().setProduction(prod)
        
        
    @execute_when("sema")
    def text(self) -> str:
        print("get text: not implemented.")

    @execute_when("sema")
    def getText(self):
        if self.content is None:
            return ""
        assert isinstance(self.content, str)
        return self.content


@execute_when("parse", "gen_ast")
def newParserRule(prod = None) -> ParserRule:
    g = ParserRule(prod)
    g.name = sys._getframe(3).f_code.co_name
    return g


@execute_when("lex", "parse", "gen_ast")
def newTerminalRule(prod = None) -> TerminalRule:
    g = TerminalRule(prod)
    g.name = sys._getframe(3).f_code.co_name
    return g
    
    



