from typing import Type, List, Dict, Literal, Callable, Tuple, Any
from types import FunctionType, MethodType, ModuleType
import inspect
import copy
import ast as py_ast
import astunparse
from .RuleDefinationTransformer import LexLexTransformer, ParseParseTransformer, LexSemaTransformer, ParseSemaTransformer, ExecutionTimeError
import logging
import sys
import ply.lex as lex
import ply.yacc as yacc
import os


class FeGenLexer:
    def __init__(self, module):
        self.module = module
        outputdir = os.path.join(os.path.dirname(__file__), self.module.__name__)
        self.lexer = lex.lex(module=self.module, debug=False, outputdir=outputdir)

class FeGenParser:
    def __init__(self, module, lexer: FeGenLexer):
        self.module = module
        self.lexer = lexer
        outputdir = os.path.join(os.path.dirname(__file__), self.module.__name__)
        self.parser = yacc.yacc(module=self.module, debug=True, outputdir=outputdir)

    def parse(self, code):
        res = self.parser.parse(code)
        return res 

class FeGenGrammar:
    """
        base class of all grammar class
    """    
    def __init__(self):
        self.plymodule = ModuleType("PLYModule", "Generated by FeGenGrammar")
        # mkdir for plymodule
        outputdir = os.path.join(os.path.dirname(__file__), self.plymodule.__name__)
        # set attr for plymodule
        setattr(self.plymodule, "__file__", outputdir)
        setattr(self.plymodule, "__package__", __package__+".PLYModule")
        if not os.path.exists(outputdir):
            os.mkdir(outputdir)
        # initialize lexer and parser
        self.lexerobj = None
        self.parserobj = None

    def __update_rules(self, self_copy):
        # declare temporary rules used in fake execution for rules generating
        temp_lexer = lambda self: TerminalRule()
        temp_parser = lambda self: ParserRule()
        for name in ExecutionEngine.lexerRuleFunc.keys():
            setattr(self_copy, name, MethodType(temp_lexer, self_copy))
        for name in ExecutionEngine.parserRuleFunc.keys():
            setattr(self_copy, name, MethodType(temp_parser, self_copy))
    
    def __capture_locals(func: FunctionType, *args, **kwargs):
        """execute and capture locals of func"""
        locals_dict = {}
        original_trace = sys.gettrace()
        
        def trace_function(frame, event, arg):
            if event == 'return' and frame.f_code == func.__code__:
                locals_dict.update(frame.f_locals)
            return trace_function
        
        sys.settrace(trace_function)
        try:
            res = func(*args, **kwargs) # execute
        finally:
            sys.settrace(original_trace)  # resume trace function
        
        return (res, locals_dict)
    
    def __eliminate_indent(source: str) -> Tuple[str, int]:
        lines = source.split('\n')
        indent = len(source)
        for line in lines:
            if len(line.strip()) == 0:
                continue
            indent = min(indent, len(line) - len(line.lstrip()))
        source = '\n'.join([line[indent:] for line in lines])

        
        return source, indent


    def __eliminate_decorators(source: str) -> Tuple[str, int]:
        lines = source.split('\n')
        num_decorators = 0
        for line in lines:
            if len(line) > 0 and line[0] == '@':
                num_decorators += 1
            else:
                break
        source = '\n'.join(lines[num_decorators:])
        return source, num_decorators

    
    def lexer(self) -> FeGenLexer:
        if self.lexerobj is not None:
            return self.lexerobj
        from .ExecuteEngine import LexerProdGen
       
        """return lexer of attribute grammar
        """
        
        # process source code and generate code for lexer
        ExecutionEngine.WHEN = "lex"
        for name, lexer_rule_defination in ExecutionEngine.lexerRuleFunc.items():
            # collect file, line and col
            lines, start_line = inspect.getsourcelines(lexer_rule_defination)
            file = inspect.getsourcefile(lexer_rule_defination)
            source = ''.join(lines)
            source, col_offset = FeGenGrammar.__eliminate_indent(source)
            source, inc_lineno = FeGenGrammar.__eliminate_decorators(source)
            start_line += inc_lineno
            
            # get ast of source code
            parsed: py_ast.AST = py_ast.parse(source=source)
            anotherParsed = copy.copy(parsed) 
            
            # collect env
            env: Dict[str, Any] = lexer_rule_defination.__globals__.copy()
            func_freevar_names: List[str] = list(lexer_rule_defination.__code__.co_freevars)
            func_freevar_cells: List[Any] = [v.cell_contents for v in lexer_rule_defination.__closure__] if lexer_rule_defination.__closure__ else []
            assert len(func_freevar_names) == len(func_freevar_cells)
            env.update(dict(zip(func_freevar_names, func_freevar_cells)))
            self_copy = copy.copy(self)
            self.__update_rules(self_copy)
            env.update({"self": self_copy})
            
            # call transformer
            lexlextrans = LexLexTransformer(
                when=ExecutionEngine.WHEN, func_name=name, file=file, start_lineno=start_line, start_column=col_offset, env=env
            )
            lexlexfuncast = lexlextrans.visit(parsed)
            lexsemafunc_code_str = astunparse.unparse(lexlexfuncast)
            lexsemafunc_code = compile(lexsemafunc_code_str, f"lexer_rule_{name}", mode = "exec")
            exec(lexsemafunc_code, env)
            lex_func: FunctionType = env[name]
            ExecutionEngine.lexerRulesWhenLex[name] = lex_func
            logging.debug(f"Code generated for lex function {name}: " + lexsemafunc_code_str)
            
        # update lex functions of self
        for name, lex_func in ExecutionEngine.lexerRulesWhenLex.items():
            setattr(self, name, MethodType(lex_func, self))
        
        # generate lex rules
        # mapping function name and local variables
        lexrule_list: List[TerminalRule] = []
        locals_list: List[dict] = []
        for name, lexDef in ExecutionEngine.lexerRulesWhenLex.items():
            # execute lex function 
            lexRule, local_vars = FeGenGrammar.__capture_locals(lexDef, self)
            assert isinstance(lexRule, TerminalRule)
            lexRule.name = name
            lexrule_list.append(lexRule)
            locals_list.append(local_vars)
        
        
        attr_dict = self.plymodule.__dict__
        # insert tokens tuple
        attr_dict.update({"tokens": tuple(ExecutionEngine.lexerRulesWhenLex.keys())})
        gen = LexerProdGen()
        # insert lex defination
        for lexRule in lexrule_list:
            name = lexRule.name
            prod = lexRule.production
            lexprod = gen(prod)
            attr_dict.update({"t_" + name:  lexprod})
        # insert ignore and skip
        # TODO: skip
        def t_error(t):
            print(f"Illegal character '{t.value[0]}'")
            t.lexer.skip(1)

        attr_dict.update({"t_error": t_error, "t_ignore": ' \t'})

        # generate PLY lexer
        self.lexerobj = FeGenLexer(self.plymodule)
        return self.lexerobj
    
    def parser(self, lexer: FeGenLexer) -> FeGenParser:
        if self.parserobj is not None:
            return self.parserobj
        from .ExecuteEngine import ParserProdGen
        # process source code and generate code for lexer
        ExecutionEngine.WHEN = "parse"
        for name, parser_rule_defination in ExecutionEngine.parserRuleFunc.items():
            # collect file, line and col
            lines, start_line = inspect.getsourcelines(parser_rule_defination)
            file = inspect.getsourcefile(parser_rule_defination)
            source = ''.join(lines)
            source, col_offset = FeGenGrammar.__eliminate_indent(source)
            source, inc_lineno = FeGenGrammar.__eliminate_decorators(source)
            start_line += inc_lineno
            
            # get ast of source code
            parsed: py_ast.AST = py_ast.parse(source=source)
            anotherParsed = copy.copy(parsed) 
            
            # collect env
            env: Dict[str, Any] = parser_rule_defination.__globals__.copy()
            func_freevar_names: List[str] = list(parser_rule_defination.__code__.co_freevars)
            func_freevar_cells: List[Any] = [v.cell_contents for v in parser_rule_defination.__closure__] if parser_rule_defination.__closure__ else []
            assert len(func_freevar_names) == len(func_freevar_cells)
            env.update(dict(zip(func_freevar_names, func_freevar_cells)))
            self_copy = copy.copy(self)
            self.__update_rules(self_copy)
            env.update({"self": self_copy})
            
            # call transformer
            parsetrans = LexLexTransformer(
                when=ExecutionEngine.WHEN, func_name=name, file=file, start_lineno=start_line, start_column=col_offset, env=env
            )
            parseparsefuncast = parsetrans.visit(parsed)
            parseparsefunc_code_str = astunparse.unparse(parseparsefuncast)
            parseparsefunc_code = compile(parseparsefunc_code_str, f"parser_rule_{name}", mode = "exec")
            exec(parseparsefunc_code, env)
            parse_func: FunctionType = env[name]
            ExecutionEngine.parserRuleseWhenParse[name] = parse_func
            logging.debug(f"Code generated for parser function {name}: " + parseparsefunc_code_str)
            
        # update parse functions of self
        for name, parse_func in ExecutionEngine.parserRuleseWhenParse.items():
            setattr(self, name, MethodType(parse_func, self))
        
        # generate parse rules
        # mapping function name and local variables
        parser_rule_list: List[ParserRule] = []
        locals_list: List[dict] = []
        for name, parse_func in ExecutionEngine.parserRuleseWhenParse.items():
            # execute lex function 
            parseRule, local_vars = FeGenGrammar.__capture_locals(parse_func, self)
            assert isinstance(parseRule, ParserRule)
            parseRule.name = name
            parser_rule_list.append(parseRule)
            locals_list.append(local_vars)
        
        
        attr_dict = self.plymodule.__dict__
        gen = ParserProdGen(attr_dict)
        # insert parse defination
        for parser_rule in parser_rule_list:
            gen(parser_rule)
        # generate PLY lexer
        self.parserobj = FeGenParser(self.plymodule, lexer)
        return self.parserobj


class Production:
    pass


class ExecutionEngine:
    """Stores global variables
    """
    WHEN: Literal['lex', 'parse', 'sema'] = "lex"
    GRAMMAR_CLS = None
    # method that decorated by lexer
    lexerRuleFunc : Dict[str, Callable] = {}
    # method that decorated by parser
    parserRuleFunc : Dict[str, Callable] = {}
    
    parserRuleseWhenParse : Dict[str, Callable] = {}
    parserRulesWhenSema : Dict[str, Callable] = {}
    lexerRulesWhenLex : Dict[str, Callable] = {}
    lexerRulesWhenSema : Dict[str, Callable] = {}
    skipRules : Dict[str, Callable] = {}




def parser(parser_rule_defination: FunctionType):
    """An decorator to mark a function in a subclass of FeGenGrammar that defines a parse rule, ExecutionEngine.WHEN decides action of function.

    Args:
        parser_rule_defination (FunctionType): lex defining function
    """
    # assert function only have one parameter: self
    sig = inspect.signature(parser_rule_defination).parameters
    assert len(sig) == 1 and f"lexer defining function should only have one parameter: self"
    name = parser_rule_defination.__name__
    ExecutionEngine.parserRuleFunc[name] = parser_rule_defination
    return parser_rule_defination


def lexer(lexer_rule_defination: FunctionType):
    """An decorator to mark a function in a subclass of FeGenGrammar that defines a lex rule, ExecutionEngine.WHEN decides action of function.

    Args:
        lexer_rule_defination (FunctionType): lex defining function
    """
    # assert function only have one parameter: self
    sig = inspect.signature(lexer_rule_defination).parameters
    assert len(sig) == 1 and f"lexer defining function should only have one parameter: self"
    name = lexer_rule_defination.__name__
    ExecutionEngine.lexerRuleFunc[name] = lexer_rule_defination
    return lexer_rule_defination


def skip(skip_rule_defination):
    def warp(*args, **kwargs):
        name = skip_rule_defination.__name__
        ExecutionEngine.lexerRulesWhenLex[name] = skip_rule_defination
        return skip_rule_defination(*args, **kwargs)
    return warp


class ExecutableWarpper:
    def __init__(self, executable: FunctionType, whenexecute: Literal['lex', 'parse', 'sema'] | Tuple[Literal['lex', 'parse', 'sema']]):
        self.executable = executable
        self.whenexecute = whenexecute

    def __call__(self, *args, **kwds):
        if isinstance(self.whenexecute, Tuple):
            flag = ExecutionEngine.WHEN in self.whenexecute
        else:
           flag = ExecutionEngine.WHEN == self.whenexecute 
        if flag:
            return self.executable(*args, **kwds)
        else:
            raise ExecutionTimeError(self.executable, "Function execute in wrong time, expected in {when} time, but now it is time to {time}".format(when=self.whenexecute, time=ExecutionEngine.WHEN))

def execute_when(when: Literal['lex', 'parse', 'sema'] | Tuple[Literal['lex', 'parse', 'sema']]):
    """mark function to execute at correct time
    """
    def decorator(func):
        f = lambda *args, **kwds: ExecutableWarpper(func, when)(*args, **kwds)
        setattr(f, "execute_when", when)
        return f
    return decorator

class ChatSet(Production):
    """
        char_set("A-Z") --> [A-Z]
    """
    def __init__(self, charset: str):
        super().__init__()
        self.charset = charset

def char_set(charset: str):
    return ChatSet(charset)

class ZeroOrMore(Production):
    """
        zero_or_more(A) --> A*
    """
    def __init__(self, rule: "Rule"):
        super().__init__()
        self.rule = rule

def zero_or_more(rule: "Rule"):
    return ZeroOrMore(rule)


class OneOrMore(Production):
    """
        one_or_more(A) --> A+ 
    """
    def __init__(self, rule: "Rule"):
        super().__init__()
        self.rule = rule

def one_or_more(rule: "Rule"):
    return OneOrMore(rule)


class Concat(Production):
    """
        concat(A, B) -->  A B
    """
    def __init__(self, *args):
        super().__init__()
        self.rules : List[Rule] = args

def concat(*args):
    return Concat(*args)

class Alternate(Production):
    """
        alternate(A, B) --> A | B
    """
    def __init__(self, *args):
        super().__init__()
        self.alts : List[FunctionType] = args


def alternate(*args):
    return Alternate(*args)


class Attribute:
    def __init__(self, name: str, ty: Type, init = None):
        self.name = name
        self.ty = ty
        self.value = init

    def set(self, value):
        assert (isinstance(value, self.ty) or value is None) and f"mismatch type."
        self.value = value

class Rule:
    def __init__(self, production = None):
        self.production = None
        self.name = "UNKNOWN"
        self.setProduction(production)
        
    def setProduction(self, prod):
        self.production = prod


class ParserRule(Rule):
    
    def __init__(self, production = None):
        super().__init__(production)
        self.attributes : Dict[str, Attribute] = []
        self.visited = False
        self.children : List[Rule] = []
    
    @execute_when("parse")
    def setProduction(self, prod):
        super().setProduction(prod)
    
    
    @execute_when("sema")
    def new_attr(self, name: str, ty: Type, init = None):
        assert name not in self.attributes and f"Attribute {name} already exists."
        attr = Attribute(name, ty, init)
        self.attributes[name] = attr
        return attr
    
    
    @execute_when("sema")
    def set_attr(self, name: str, value):
        assert name not in self.attributes and f"Attribute {name} does exist."
        attr = self.attributes[name]
        attr.set(value)
    
    
    @execute_when("sema")
    def get_attr(self, name: str):
        assert name in self.attributes and f"Attribute {name} does not exist."
        if not self.visited:
            self.visit()
        return self.attributes[name]

    
    @execute_when("sema")
    def visit(self):
        """
            visit tree node 
        """
        self.visited = True
        # TODO: VISIT

class TerminalRule(Rule):
    def __init__(self, production = None):
        super().__init__(production)

    
    @execute_when(("lex", "parse"))
    def setProduction(self, prod):
        return super().setProduction(prod)
        
        
    @execute_when("sema")
    def text(self) -> str:
        print("get text: not implemented.")

@execute_when("parse")
def newParserRule() -> ParserRule:
    g = ParserRule()
    g.name = sys._getframe(3).f_code.co_name
    return g

@execute_when(("lex", "parse"))
def newTerminalRule(prod = None) -> TerminalRule:
    g = TerminalRule(prod)
    g.name = sys._getframe(3).f_code.co_name
    return g
    
    



